"""
Command processor with platform-aware access control
"""

import logging
from typing import List, Optional, Tuple

from app.core.constants import COMMAND_DESCRIPTIONS, MESSAGES_FA
from app.core.name_mapping import get_friendly_model_name
from app.models.session import ChatSession
from app.services.platform_manager import platform_manager

logger = logging.getLogger(__name__)


class CommandProcessor:
    """Processes bot commands with platform-aware access control"""

    def __init__(self):
        self.commands = {
            "start": self.handle_start,
            "help": self.handle_help,
            "status": self.handle_status,
            "clear": self.handle_clear,
            "model": self.handle_model,
            "models": self.handle_models,
            "settings": self.handle_settings,
        }

    def is_command(self, text: str) -> bool:
        """Check if text is a command"""
        if not text:
            return False
        return text.startswith("/") or text.startswith("!")

    def parse_command(self, text: str) -> Tuple[Optional[str], List[str]]:
        """Parse command and arguments"""
        if not self.is_command(text):
            return None, []

        text = text.lstrip("/!").strip()
        parts = text.split()

        if not parts:
            return None, []

        command = parts[0].lower()
        args = parts[1:] if len(parts) > 1 else []

        return command, args

    def can_use_command(self, command: str, platform: str) -> bool:
        """Check if platform can use command"""
        allowed_commands = platform_manager.get_allowed_commands(platform)
        return command in allowed_commands

    async def process_command(self, session: ChatSession, text: str) -> str:
        """Process command and return response"""
        command, args = self.parse_command(text)

        if not command:
            return MESSAGES_FA["command_unknown"].format(command="")

        # Check if command is allowed for platform
        if not self.can_use_command(command, session.platform):
            allowed = platform_manager.get_allowed_commands(session.platform)
            commands_list = "\n".join([f"â€¢ /{c}" for c in allowed])
            return MESSAGES_FA["command_not_available_platform"].format(
                command=command, platform=session.platform.title(), commands=commands_list
            )

        # Execute command
        if command in self.commands:
            handler = self.commands[command]
            try:
                return await handler(session, args)
            except Exception as e:
                logger.error(f"Error executing command {command}: {e}", exc_info=True)
                return f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ±: {str(e)}"

        return MESSAGES_FA["command_unknown"].format(command=command)

    async def handle_start(self, session: ChatSession, args: List[str]) -> str:
        """Handle /start command"""
        config = platform_manager.get_config(session.platform)
        friendly_model = session.current_model_friendly  # âœ“ Show friendly name

        if session.platform == "internal":
            welcome = MESSAGES_FA["welcome_internal"].format(model=friendly_model)
            if session.is_admin:
                welcome += MESSAGES_FA["welcome_internal_admin"]
            return welcome
        else:
            return MESSAGES_FA["welcome_telegram"].format(
                model=friendly_model, rate_limit=config.rate_limit  # âœ“ Show friendly name
            )

    async def handle_help(self, session: ChatSession, args: List[str]) -> str:
        """Handle /help command"""
        allowed_commands = platform_manager.get_allowed_commands(session.platform)
        config = platform_manager.get_config(session.platform)
        friendly_model = session.current_model_friendly  # âœ“ Show friendly name

        help_text = "ğŸ“š **Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…ÙˆØ¬ÙˆØ¯:**\n\n"
        for cmd in allowed_commands:
            if cmd in COMMAND_DESCRIPTIONS:
                help_text += f"/{cmd} - {COMMAND_DESCRIPTIONS[cmd]}\n"

        help_text += "\nğŸ’¡ **Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ (Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯):**\n"
        for cmd in allowed_commands:
            help_text += f"/{cmd}  "
        help_text += "\n"

        help_text += "\nğŸ“Š **Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ù„ØªÙØ±Ù…:**\n"
        if session.platform == "internal":
            help_text += "â€¢ Ù¾Ù„ØªÙØ±Ù…: Ø¯Ø§Ø®Ù„ÛŒ (Ø®ØµÙˆØµÛŒ)\n"
            help_text += "â€¢ ØªØºÛŒÛŒØ± Ù…Ø¯Ù„: âœ… ÙØ¹Ø§Ù„\n"
            help_text += f"â€¢ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ: {friendly_model}\n"  # âœ“ Show friendly name
            help_text += f"â€¢ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {len(config.available_models)}\n"
            help_text += f"â€¢ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø±Ø¹Øª: {config.rate_limit} Ù¾ÛŒØ§Ù…/Ø¯Ù‚ÛŒÙ‚Ù‡\n"
            help_text += f"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡: {config.max_history} Ù¾ÛŒØ§Ù…\n"
        else:
            help_text += "â€¢ Ù¾Ù„ØªÙØ±Ù…: ØªÙ„Ú¯Ø±Ø§Ù… (Ø¹Ù…ÙˆÙ…ÛŒ)\n"
            help_text += "â€¢ ØªØºÛŒÛŒØ± Ù…Ø¯Ù„: âœ… ÙØ¹Ø§Ù„\n"
            help_text += f"â€¢ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ: {friendly_model}\n"  # âœ“ Show friendly name
            help_text += f"â€¢ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {len(config.available_models)}\n"
            help_text += f"â€¢ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø±Ø¹Øª: {config.rate_limit} Ù¾ÛŒØ§Ù…/Ø¯Ù‚ÛŒÙ‚Ù‡\n"
            help_text += f"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡: {config.max_history} Ù¾ÛŒØ§Ù…\n"
            help_text += "\nğŸ’¡ Ø§Ø² /model Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"

        return help_text

    async def handle_status(self, session: ChatSession, args: List[str]) -> str:
        """Handle /status command"""
        config = platform_manager.get_config(session.platform)
        friendly_model = session.current_model_friendly  # âœ“ Show friendly name

        status_text = (
            f"ğŸ“Š **ÙˆØ¶Ø¹ÛŒØª Ù†Ø´Ø³Øª:**\n\n"
            f"â€¢ Ù¾Ù„ØªÙØ±Ù…: {session.platform.title()}\n"
            f"â€¢ Ù†ÙˆØ¹: {'Ø®ØµÙˆØµÛŒ (Ø¯Ø§Ø®Ù„ÛŒ)' if config.type == 'private' else 'Ø¹Ù…ÙˆÙ…ÛŒ'}\n"
            f"â€¢ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ: {friendly_model}\n"  # âœ“ Show friendly name
            f"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§: {session.total_message_count}\n"
            f"â€¢ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø±Ø¹Øª: {config.rate_limit}/Ø¯Ù‚ÛŒÙ‚Ù‡\n"
        )

        if session.is_admin:
            status_text += "â€¢ Ù†Ù‚Ø´: Ø§Ø¯Ù…ÛŒÙ† ğŸ‘‘\n"

        return status_text

    async def handle_clear(self, session: ChatSession, args: List[str]) -> str:
        """
        Handle /clear command - marks all messages as cleared in database.

        Architecture:
        - Messages remain in DB for analytics (not deleted)
        - Sets cleared_at timestamp on all existing messages
        - Clears in-memory history for AI context
        - Future messages will not include cleared messages in context
        """
        from datetime import datetime

        from app.models.database import Message, get_db_session

        # Mark all messages as cleared in database
        try:
            db = get_db_session()
            clear_time = datetime.utcnow()

            # Update all uncleared messages for this user
            db.query(Message).filter(
                Message.platform == session.platform,
                Message.user_id == session.user_id,
                Message.team_id == session.team_id if session.team_id else Message.team_id.is_(None),
                Message.cleared_at.is_(None),  # Only update uncleared messages
            ).update({"cleared_at": clear_time})

            db.commit()
            logger.info(
                f"Marked messages as cleared for user={session.user_id} "
                f"platform={session.platform} team={session.team_id}"
            )
        except Exception as e:
            logger.error(f"Error marking messages as cleared in DB: {e}")
            db.rollback()
            # Continue anyway - at least clear in-memory

        # Clear in-memory history (for AI context)
        session.clear_history()

        return MESSAGES_FA["session_cleared"]

    async def handle_model(self, session: ChatSession, args: List[str]) -> str:
        """Handle /model command - accepts friendly names, aliases, or technical IDs"""

        if not args:
            # Show current model and available models (ALL AS FRIENDLY NAMES)
            friendly_models = platform_manager.get_available_models_friendly(session.platform)
            current_friendly = session.current_model_friendly

            models_text = f"**Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ:** {current_friendly}\n\n"  # âœ“ Friendly name
            models_text += "**Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:**\n"

            for model in friendly_models:  # âœ“ All friendly names
                if model == current_friendly:
                    models_text += f"â€¢ **{model}** â† ÙØ¹Ù„ÛŒ\n"
                else:
                    models_text += f"â€¢ {model}\n"

            models_text += "\nğŸ’¡ **Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ (Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯):**\n"

            # Add copiable commands based on platform
            if session.platform == "telegram":
                models_text += "â€¢ /model gemini - Gemini Flash\n"
                models_text += "â€¢ /model deepseek - DeepSeek v3\n"
                models_text += "â€¢ /model mini - GPT-4o Mini\n"
                models_text += "â€¢ /model gemma - Gemma 3\n"
            else:
                models_text += "â€¢ /model claude - Claude Sonnet 4\n"
                models_text += "â€¢ /model gpt5 - GPT-5\n"
                models_text += "â€¢ /model gpt4 - GPT-4.1\n"
                models_text += "â€¢ /model mini - GPT-4o Mini\n"
                models_text += "â€¢ /model grok - Grok 4\n"

            return models_text

        # User wants to switch model - support multi-word names like "Gemini 2.0 Flash"
        model_input = " ".join(args)

        # Resolve to technical ID (handles friendly names, aliases, technical IDs)
        technical_model = platform_manager.resolve_model_name(model_input, session.platform)

        if not technical_model:
            # Invalid model - show available friendly names with copiable commands
            friendly_models = platform_manager.get_available_models_friendly(session.platform)
            error_text = MESSAGES_FA["model_invalid"].format(model=model_input) + "\n\n"
            error_text += "**Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:**\n"
            error_text += "\n".join([f"â€¢ {m}" for m in friendly_models])  # âœ“ Friendly names

            error_text += "\n\nğŸ’¡ **Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ (Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯):**\n"
            if session.platform == "telegram":
                error_text += "â€¢ /model gemini\nâ€¢ /model deepseek\nâ€¢ /model mini\nâ€¢ /model gemma"
            else:
                error_text += "â€¢ /model claude\nâ€¢ /model gpt5\nâ€¢ /model gpt4\nâ€¢ /model mini"

            return error_text

        # Store technical ID internally, show friendly name to user
        session.current_model = technical_model
        friendly_name = get_friendly_model_name(technical_model)
        return MESSAGES_FA["model_switched"].format(model=friendly_name)  # âœ“ Friendly name

    async def handle_models(self, session: ChatSession, args: List[str]) -> str:
        """Handle /models command - shows all as friendly names"""
        friendly_models = platform_manager.get_available_models_friendly(
            session.platform
        )  # âœ“ Get friendly names
        current_friendly = session.current_model_friendly

        if session.platform == "telegram":
            models_text = "ğŸ¤– **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…:**\n\n"
        else:
            models_text = "ğŸ¤– **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ (Ø¯Ø§Ø®Ù„ÛŒ):**\n\n"

        for model in friendly_models:  # âœ“ All friendly names
            if model == current_friendly:
                models_text += f"â€¢ **{model}** â† ÙØ¹Ù„ÛŒ\n"
            else:
                models_text += f"â€¢ {model}\n"

        models_text += "\nğŸ’¡ **Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ (Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯):**\n"

        # Add copiable commands based on platform
        if session.platform == "telegram":
            models_text += "â€¢ /model gemini - Gemini Flash\n"
            models_text += "â€¢ /model flash-2.5 - Gemini 2.5 Flash\n"
            models_text += "â€¢ /model deepseek - DeepSeek v3\n"
            models_text += "â€¢ /model mini - GPT-4o Mini\n"
            models_text += "â€¢ /model gemma - Gemma 3 1B\n"
        else:
            models_text += "â€¢ /model claude - Claude Sonnet 4\n"
            models_text += "â€¢ /model gpt5 - GPT-5\n"
            models_text += "â€¢ /model gpt4 - GPT-4.1\n"
            models_text += "â€¢ /model mini - GPT-4o Mini\n"
            models_text += "â€¢ /model search - GPT-4o Search\n"
            models_text += "â€¢ /model gemini - Gemini 2.5 Flash\n"
            models_text += "â€¢ /model grok - Grok 4\n"
            models_text += "â€¢ /model deepseek - DeepSeek v3\n"
            models_text += "â€¢ /model llama - Llama 4 Maverick\n"

        return models_text

    async def handle_settings(self, session: ChatSession, args: List[str]) -> str:
        """Handle /settings command (private only)"""
        if session.platform != "internal":
            return MESSAGES_FA["internal_only"]

        friendly_model = session.current_model_friendly  # âœ“ Show friendly name

        settings_text = (
            "âš™ï¸ **ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ø±Ø¨Ø±:**\n\n"
            f"â€¢ Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ø±Ø¨Ø±: {session.user_id}\n"
            f"â€¢ Ù¾Ù„ØªÙØ±Ù…: {session.platform}\n"
            f"â€¢ Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶: {friendly_model}\n"  # âœ“ Friendly name
            f"â€¢ ÙˆØ¶Ø¹ÛŒØª Ø§Ø¯Ù…ÛŒÙ†: {'Ø¨Ù„Ù‡' if session.is_admin else 'Ø®ÛŒØ±'}\n\n"
            "Ø§Ù…Ú©Ø§Ù† Ø³ÙØ§Ø±Ø´ÛŒâ€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ..."
        )

        return settings_text


# Global instance
command_processor = CommandProcessor()
